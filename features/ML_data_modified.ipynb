{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddZz56zUIz0H",
        "outputId": "d07591f4-c123-42df-ca41-e41a92680adb"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. mon_standard.pkl > array code\n",
        "\n"
      ],
      "metadata": {
        "id": "6a7b3a0l2ep4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "USE_SUBLABEL = False\n",
        "URL_PER_SITE = 10\n",
        "TOTAL_URLS   = 950\n",
        "\n",
        "# Load the pickle file\n",
        "print(\"Loading datafile...\")\n",
        "with open(\"/content/drive/MyDrive/기계학습/mon_standard.pkl\", 'rb') as fi: # Path to mon_standard.pkl in Colab\n",
        "    data = pickle.load(fi)\n",
        "\n",
        "X1 = [] # Array to store instances (timestamps) - 19,000 instances, e.g., [[0.0, 0.5, 3.4, ...], [0.0, 4.5, ...], [0.0, 1.5, ...], ... [... ,45.8]]\n",
        "X2 = [] # Array to store instances (direction*size) - size information\n",
        "y = [] # Array to store the site of each instance - 19,000 instances, e.g., [0, 0, 0, 0, 0, 0, ..., 94, 94, 94, 94, 94]\n",
        "\n",
        "# Differentiate instances and sites, and store them in the respective x and y arrays\n",
        "# x array (direction*timestamp), y array (site label)\n",
        "for i in range(TOTAL_URLS):\n",
        "    if USE_SUBLABEL:\n",
        "        label = i\n",
        "    else:\n",
        "        label = i // URL_PER_SITE # Calculate which site's URL the current URL being processed belongs to and set that value as the label. Thus, URLs fetched from the same site are labeled identically.\n",
        "    for sample in data[i]:\n",
        "        size_seq = []\n",
        "        time_seq = []\n",
        "        for c in sample:\n",
        "            dr = 1 if c > 0 else -1\n",
        "            time_seq.append(abs(c))\n",
        "            size_seq.append(dr * 512)\n",
        "        X1.append(time_seq)\n",
        "        X2.append(size_seq)\n",
        "        y.append(label)\n",
        "size = len(y)\n",
        "\n",
        "print(f'Total samples: {size}') # Output: 19000\n"
      ],
      "metadata": {
        "id": "5mfwrTwPtd36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "289e21b3-b7ca-46fe-d323-34ddf1a2b884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading datafile...\n",
            "Total samples: 19000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Features\n",
        "num_total_packets = [] # feature 1\n",
        "sum_packets = [] # feature 2\n",
        "num_incoming_packets = [] # feature 3\n",
        "frac_incoming_packets = [] # feature 4\n",
        "num_outgoing_packets=[] # feature 5\n",
        "frac_outgoing_packets=[] # feature 6\n",
        "average_incoming_ordering=[] # feature 7\n",
        "std_dev_incoming_ordering=[] # feature 8\n",
        "average_outgoing_ordering=[] # feature 9\n",
        "std_dev_outgoing_ordering=[] # feature 10\n",
        "alternative_packets_per_second_sum = [] # feature 11\n",
        "mean_of_the_sequence=[] # feature 12"
      ],
      "metadata": {
        "id": "Y428A-fkputW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "for size_seq in X2:\n",
        "    # 1. Total number of pacekts\n",
        "    total = len(size_seq)\n",
        "    num_total_packets.append(total)\n",
        "\n",
        "    # 2. Sum of packets (absolute value gives the size regardless of direction)\n",
        "    sum_pckts = sum(abs(size) for size in size_seq)\n",
        "    sum_packets.append(sum_pckts)\n",
        "\n",
        "    # 3. Number of incoming packets\n",
        "    incoming = sum(1 for size in size_seq if size < 0)\n",
        "    num_incoming_packets.append(incoming)\n",
        "\n",
        "    # 4. Number of incoming packets as a fraction of the total number of packets\n",
        "    frac_incoming = incoming / total if total > 0 else 0\n",
        "    frac_incoming_packets.append(frac_incoming)\n",
        "\n",
        "    # 5. Number of outgoing packets\n",
        "    outgoing = sum(1 for size in size_seq if size > 0)\n",
        "    num_outgoing_packets.append(outgoing)\n",
        "\n",
        "    # 6. Number of outgoing packets as a fraction of the total number of packets\n",
        "    frac_outgoing = outgoing / total if total > 0 else 0\n",
        "    frac_outgoing_packets.append(frac_outgoing)\n",
        "\n",
        "    # 7. Average of the incoming packet ordering list\n",
        "    incoming_ordering_list = []\n",
        "    for idx, size in enumerate(size_seq):\n",
        "        if size < 0:\n",
        "            incoming_ordering_list.append(idx)\n",
        "\n",
        "    average_incoming_ordering.append(np.mean(incoming_ordering_list))\n",
        "\n",
        "    # 8. Standard deviation of the incoming packet ordering list\n",
        "    std_dev_incoming_ordering.append(np.std(incoming_ordering_list))\n",
        "\n",
        "    # 9. Average of the outgoing packet ordering list\n",
        "    outgoing_ordering_list = []\n",
        "    for idx, size in enumerate(size_seq):\n",
        "        if size > 0:\n",
        "            outgoing_ordering_list.append(idx)\n",
        "    average_outgoing_ordering.append(np.mean(outgoing_ordering_list))\n",
        "\n",
        "    # 10. Standard deviation of the outgoing packet ordering list\n",
        "    std_dev_outgoing_ordering.append(np.std(outgoing_ordering_list))\n",
        "\n",
        "    # 11. mean of the sequence\n",
        "    chunks = [size_seq[i:i + 20] for i in range(0, len(size_seq), 20)]\n",
        "    outgoing_counts = [sum(1 for elem in chunk if elem > 0) for chunk in chunks]\n",
        "    filtered_array = [element for element in outgoing_counts if element != 0]\n",
        "    average_outgoing_counts = sum(filtered_array) / len(filtered_array)\n",
        "    mean_of_the_sequence.append(average_outgoing_counts)"
      ],
      "metadata": {
        "id": "4WtFNYWFM7V_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Sum of alternative number packets per second\n",
        "alternative_packets_per_second_sum = []\n",
        "\n",
        "for time_seq, size_seq in zip(X1, X2):\n",
        "    packets_per_subset = len(size_seq) // 20 # 20 even-sized subsets\n",
        "    subset_sums = []\n",
        "\n",
        "    for i in range(0, len(size_seq), packets_per_subset):\n",
        "        start_index = i\n",
        "        end_index = min(i + packets_per_subset, len(size_seq))\n",
        "\n",
        "        time_interval = time_seq[end_index - 1] - time_seq[start_index]\n",
        "        time_interval = max(time_interval, 0.001) # Ensure that the time interval does not become zero.\n",
        "\n",
        "        packets_per_second = (end_index - start_index) / time_interval\n",
        "        subset_sums.append(packets_per_second)\n",
        "\n",
        "        if (end_index == packets_per_subset*20):\n",
        "            break\n",
        "\n",
        "    alternative_packets_per_second_sum.append(sum(subset_sums))"
      ],
      "metadata": {
        "id": "Rf-5L51BN7rT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"feature 1: {num_total_packets}\")\n",
        "print(f\"feature 2: {sum_packets}\")\n",
        "print(f\"feature 3: {num_incoming_packets}\")\n",
        "print(f\"feature 4: {frac_incoming_packets}\")\n",
        "print(f\"feature 5: {num_outgoing_packets}\")\n",
        "print(f\"feature 6: {frac_outgoing_packets}\")"
      ],
      "metadata": {
        "id": "JpzV8jVeZjif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'feature 7: {average_outgoing_ordering}');\n",
        "print(f'feature 8: {std_dev_outgoing_ordering}');\n",
        "print(f'feature 9: {average_incoming_ordering}');\n",
        "print(f'feature 10: {std_dev_incoming_ordering}');\n",
        "print(f'feature 11: {mean_of_the_sequence}');\n",
        "print(f\"feature 12: {alternative_packets_per_second_sum}\")"
      ],
      "metadata": {
        "id": "duo4k-fHqlqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(num_total_packets))\n",
        "print(len(sum_packets))\n",
        "print(len(num_incoming_packets))\n",
        "print(len(frac_incoming_packets))\n",
        "print(len(num_outgoing_packets))\n",
        "print(len(frac_outgoing_packets))\n",
        "print(len(average_outgoing_ordering))\n",
        "print(len(std_dev_outgoing_ordering))\n",
        "print(len(average_incoming_ordering))\n",
        "print(len(std_dev_incoming_ordering))\n",
        "print(len(mean_of_the_sequence))\n",
        "print(len(alternative_packets_per_second_sum))"
      ],
      "metadata": {
        "id": "Nmb7Yd8lygA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "incoming_packets_first30 =[] # feature 13\n",
        "outgoing_packets_first30 = [] # feature 14\n",
        "transmission_time_Q1 = [] # feature 15\n",
        "transmission_time_Q2 = [] # feature 16\n",
        "transmission_time_Q3 = [] # feature 17\n",
        "transmission_time_Q4 = [] # feature 18"
      ],
      "metadata": {
        "id": "dRUU_biy_2D8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_packets_per_second = [] # feature 19\n",
        "mean_packets_per_second = [] # feature 20\n",
        "std_packets_per_second = [] # feature 21\n",
        "med_packets_per_second = [] # feature 22"
      ],
      "metadata": {
        "id": "OYI22cxTIv5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RAM 부족으로 이용X\n",
        "incoming_max_inter_arrival_times = [] # feature 23\n",
        "incoming_mean_inter_arrival_times = [] # feature 24\n",
        "incoming_std_inter_arrival_times = [] # feature 25\n",
        "incoming_third_quartileinter_arrival_times = [] # feature 26\n",
        "outgoing_max_inter_arrival_times = [] # feature 27\n",
        "outgoing_mean_inter_arrival_times = [] # feature 28\n",
        "outgoing_std_inter_arrival_times = [] # feature 29\n",
        "outgoing_third_quartileinter_arrival_times = [] # feature 30"
      ],
      "metadata": {
        "id": "VamY1dSrWUyU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for size_seq in X2:\n",
        "    incoming_packets = sum(1 for size in size_seq[:30] if size < 0)\n",
        "    incoming_packets_first30.append(incoming_packets)\n",
        "\n",
        "    outgoing_packets = sum(1 for size in size_seq[:30] if size > 0)\n",
        "    outgoing_packets_first30.append(outgoing_packets)\n",
        "\n",
        "print(\"incoming_packets_first30:\", incoming_packets_first30)\n",
        "print(\"outgoing_packets_first30:\", outgoing_packets_first30)"
      ],
      "metadata": {
        "id": "oHGHlsqoqc9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(X1)):\n",
        "    Q1 = np.percentile(X1[i], 25)\n",
        "    Q2 = np.percentile(X1[i], 50)\n",
        "    Q3 = np.percentile(X1[i], 75)\n",
        "    Q4 = np.percentile(X1[i], 100)\n",
        "\n",
        "    transmission_time_Q1.append(Q1)\n",
        "    transmission_time_Q2.append(Q2)\n",
        "    transmission_time_Q3.append(Q3)\n",
        "    transmission_time_Q4.append(Q4)\n",
        "\n",
        "print(\"transmission_time_Q1:\", transmission_time_Q1)\n",
        "print(\"transmission_time_Q2:\", transmission_time_Q2)\n",
        "print(\"transmission_time_Q3:\", transmission_time_Q3)\n",
        "print(\"transmission_time_Q4:\", transmission_time_Q4)"
      ],
      "metadata": {
        "id": "kx5Ip8yDCKyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "\n",
        "for i in range(len(X1)):\n",
        "    num_packets = len(X1[i]) / X1[i][-1]\n",
        "    mean_packets = statistics.mean(X1[i])\n",
        "    std_packets = statistics.stdev(X1[i])\n",
        "    med_packets = statistics.median(X1[i])\n",
        "\n",
        "    num_packets_per_second.append(num_packets)\n",
        "    mean_packets_per_second.append(mean_packets)\n",
        "    std_packets_per_second.append(std_packets)\n",
        "    med_packets_per_second.append(med_packets)\n",
        "\n",
        "print(f\"Num Packets Per Second: {num_packets_per_second}\")\n",
        "print(f\"Mean Packets Per Second: {mean_packets_per_second}\")\n",
        "print(f\"Std Packets Per Second: {std_packets_per_second}\")\n",
        "print(f\"Med Packets Per Second: {med_packets_per_second}\")"
      ],
      "metadata": {
        "id": "RjBrwM01N_Dn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = {'num_total_packets': num_total_packets,\n",
        "        'sum_packets': sum_packets,\n",
        "        'num_incoming_packets': num_incoming_packets,\n",
        "        'frac_incoming_packets': frac_incoming_packets,\n",
        "        'num_outgoing_packets': num_outgoing_packets,\n",
        "        'frac_outgoing_packets': frac_outgoing_packets,\n",
        "        'average_outgoing_ordering': average_outgoing_ordering,\n",
        "        'std_dev_outgoing_ordering': std_dev_outgoing_ordering,\n",
        "        'average_incoming_ordering': average_incoming_ordering,\n",
        "        'std_dev_incoming_ordering': std_dev_incoming_ordering,\n",
        "        'mean_of_the_sequence': mean_of_the_sequence,\n",
        "        'alternative_packets_per_second_sum': alternative_packets_per_second_sum}\n",
        "df1 = pd.DataFrame(data)\n",
        "\n",
        "print(df1.head())"
      ],
      "metadata": {
        "id": "kH3HLNU-q5v5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = {'label': y}\n",
        "df2 = pd.DataFrame(data)\n",
        "\n",
        "print(df2.head())"
      ],
      "metadata": {
        "id": "JS-3mqyDvSMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.to_csv('mon_features.csv', index=False)"
      ],
      "metadata": {
        "id": "XwdqaM0Luu4i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.to_csv('mon_labels.csv', index=False)"
      ],
      "metadata": {
        "id": "RkOIlkh3vPwK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data_modified = {'num_total_packets': num_total_packets, #1\n",
        "                 'sum_packets': sum_packets, #2\n",
        "                 'num_incoming_packets': num_incoming_packets, #3\n",
        "                 'frac_incoming_packets': frac_incoming_packets, #4\n",
        "                 'num_outgoing_packets': num_outgoing_packets, #5\n",
        "                 'frac_outgoing_packets': frac_outgoing_packets, #6\n",
        "                 'average_outgoing_ordering': average_outgoing_ordering, #7\n",
        "                 'std_dev_outgoing_ordering': std_dev_outgoing_ordering, #8\n",
        "                 'average_incoming_ordering': average_incoming_ordering, #9\n",
        "                 'std_dev_incoming_ordering': std_dev_incoming_ordering, #10\n",
        "                 'mean_of_the_sequence': mean_of_the_sequence, #11\n",
        "                 'alternative_packets_per_second_sum': alternative_packets_per_second_sum, #12\n",
        "                 'incoming_packets_first30': incoming_packets_first30, #13\n",
        "                 'outgoing_packets_first30': outgoing_packets_first30, #14\n",
        "                 'transmission_time_Q1': transmission_time_Q1, #15\n",
        "                 'transmission_time_Q2': transmission_time_Q2, #16\n",
        "                 'transmission_time_Q3': transmission_time_Q3, #17\n",
        "                 'transmission_time_Q4': transmission_time_Q4, #18\n",
        "                 'num_packets_per_second': num_packets_per_second, #19\n",
        "                 'mean_packets_per_second': mean_packets_per_second, #20\n",
        "                 'std_packets_per_second': std_packets_per_second, #21\n",
        "                 'med_packets_per_second': med_packets_per_second #22\n",
        "                 }\n",
        "df1_modified = pd.DataFrame(data_modified)\n",
        "\n",
        "print(df1_modified.head())"
      ],
      "metadata": {
        "id": "3ZAvPU71H4Kd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1_modified.to_csv('mon_features_modified1.csv', index=False)"
      ],
      "metadata": {
        "id": "8BQtmXxCH4Mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1_modified1=pd.read_csv('/content/drive/MyDrive/ML_Project/mon_features_modified1.csv')"
      ],
      "metadata": {
        "id": "k4RcOC7S0PpF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data_modified2 = {'incoming_max_inter_arrival_times': incoming_max_inter_arrival_times, #23\n",
        "                  'incoming_mean_inter_arrival_times': incoming_mean_inter_arrival_times, #24\n",
        "                  'incoming_std_inter_arrival_times': incoming_std_inter_arrival_times, #25\n",
        "                  'incoming_third_quartileinter_arrival_times': incoming_third_quartileinter_arrival_times, #26\n",
        "                  'outgoing_max_inter_arrival_times': outgoing_max_inter_arrival_times, #27\n",
        "                  'outgoing_mean_inter_arrival_times': outgoing_mean_inter_arrival_times, #28\n",
        "                  'outgoing_std_inter_arrival_times': outgoing_std_inter_arrival_times, #29\n",
        "                  'outgoing_third_quartileinter_arrival_times': outgoing_third_quartileinter_arrival_times #30\n",
        "                 }\n",
        "df1_modified2 = pd.DataFrame(data_modified2)\n",
        "\n",
        "print(df1_modified.head())"
      ],
      "metadata": {
        "id": "FynDcD0XwlWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mwmDEpIIu1zN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. unmon_standard10.pkl > array code"
      ],
      "metadata": {
        "id": "yz5mat0w2dJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "TOTAL_URLS = 10000  # total number in the dataset\n",
        "\n",
        "# Load 10,000 unmon pickle file\n",
        "print(\"Loading datafile...\")\n",
        "with open('/content/drive/MyDrive/ML_Project/unmon_standard.pkl', 'rb') as f:  # Path to unmon_standard10.pkl in Colab\n",
        "    x = pickle.load(f)\n",
        "\n",
        "size = len(x)\n",
        "print(f'Total samples: {size}')\n",
        "\n",
        "X1 = [] # Array to store instances (timestamps) - 10,000 instances, e.g., [[0.0, 0.5, 3.4, ...], [0.0, 4.5, ...], [0.0, 1.5, ...], ... [... ,45.8]]\n",
        "X2 = [] # Array to store instances (direction*size) - size information\n",
        "\n",
        "for i in range(TOTAL_URLS):\n",
        "    size_seq = []\n",
        "    time_seq = []\n",
        "    for c in x[i]:\n",
        "        dr = 1 if c > 0 else -1\n",
        "        time_seq.append(abs(c))\n",
        "        size_seq.append(dr * 512) # In the pickle file, there is no size information, so the conversion code is set to multiply by 512 uniformly.\n",
        "    X1.append(time_seq)\n",
        "    X2.append(size_seq)\n",
        "\n",
        "print(len(X1)) # Print the length of X1"
      ],
      "metadata": {
        "id": "IWfcIOZovSMl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82531c50-32d3-48a8-8e62-a9180d91e679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading datafile...\n",
            "Total samples: 10000\n",
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Features\n",
        "num_total_packets = [] # feature 1\n",
        "sum_packets = [] # feature 2\n",
        "num_incoming_packets = [] # feature 3\n",
        "frac_incoming_packets = [] # feature 4\n",
        "num_outgoing_packets=[] # feature 5\n",
        "frac_outgoing_packets=[] # feature 6\n",
        "average_incoming_ordering=[] # feature 7\n",
        "std_dev_incoming_ordering=[] # feature 8\n",
        "average_outgoing_ordering=[] # feature 9\n",
        "std_dev_outgoing_ordering=[] # feature 10\n",
        "alternative_packets_per_second_sum = [] # feature 11\n",
        "mean_of_the_sequence=[] # feature 12"
      ],
      "metadata": {
        "id": "b7fxyTK_81q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "for size_seq in X2:\n",
        "    # 1. Total number of pacekts\n",
        "    total = len(size_seq)\n",
        "    num_total_packets.append(total)\n",
        "\n",
        "    # 2. Sum of packets (absolute value gives the size regardless of direction)\n",
        "    sum_pckts = sum(abs(size) for size in size_seq)\n",
        "    sum_packets.append(sum_pckts)\n",
        "\n",
        "    # 3. Number of incoming packets\n",
        "    incoming = sum(1 for size in size_seq if size < 0)\n",
        "    num_incoming_packets.append(incoming)\n",
        "\n",
        "    # 4. Number of incoming packets as a fraction of the total number of packets\n",
        "    frac_incoming = incoming / total if total > 0 else 0\n",
        "    frac_incoming_packets.append(frac_incoming)\n",
        "\n",
        "    # 5. Number of outgoing packets\n",
        "    outgoing = sum(1 for size in size_seq if size > 0)\n",
        "    num_outgoing_packets.append(outgoing)\n",
        "\n",
        "    # 6. Number of outgoing packets as a fraction of the total number of packets\n",
        "    frac_outgoing = outgoing / total if total > 0 else 0\n",
        "    frac_outgoing_packets.append(frac_outgoing)\n",
        "\n",
        "    # 7. Average of the incoming packet ordering list\n",
        "    incoming_ordering_list = []\n",
        "    for idx, size in enumerate(size_seq):\n",
        "        if size < 0:\n",
        "            incoming_ordering_list.append(idx)\n",
        "\n",
        "    average_incoming_ordering.append(np.mean(incoming_ordering_list))\n",
        "\n",
        "    # 8. Standard deviation of the incoming packet ordering list\n",
        "    std_dev_incoming_ordering.append(np.std(incoming_ordering_list))\n",
        "\n",
        "    # 9. Average of the outgoing packet ordering list\n",
        "    outgoing_ordering_list = []\n",
        "    for idx, size in enumerate(size_seq):\n",
        "        if size > 0:\n",
        "            outgoing_ordering_list.append(idx)\n",
        "    average_outgoing_ordering.append(np.mean(outgoing_ordering_list))\n",
        "\n",
        "    # 10. Standard deviation of the outgoing packet ordering list\n",
        "    std_dev_outgoing_ordering.append(np.std(outgoing_ordering_list))\n",
        "\n",
        "    # 11. mean of the sequence\n",
        "    chunks = [size_seq[i:i + 20] for i in range(0, len(size_seq), 20)]\n",
        "    outgoing_counts = [sum(1 for elem in chunk if elem > 0) for chunk in chunks]\n",
        "    filtered_array = [element for element in outgoing_counts if element != 0]\n",
        "    average_outgoing_counts = sum(filtered_array) / len(filtered_array)\n",
        "    mean_of_the_sequence.append(average_outgoing_counts)"
      ],
      "metadata": {
        "id": "uwTLAwi-9BSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 12. Sum of alternative number packets per second\n",
        "alternative_packets_per_second_sum = []\n",
        "\n",
        "for time_seq, size_seq in zip(X1, X2):\n",
        "    packets_per_subset = len(size_seq) // 20 # 20 even-sized subsets\n",
        "    subset_sums = []\n",
        "\n",
        "    for i in range(0, len(size_seq), packets_per_subset):\n",
        "        start_index = i\n",
        "        end_index = min(i + packets_per_subset, len(size_seq))\n",
        "\n",
        "        time_interval = time_seq[end_index - 1] - time_seq[start_index]\n",
        "        time_interval = max(time_interval, 0.001) # Ensure that the time interval does not become zero.\n",
        "\n",
        "        packets_per_second = (end_index - start_index) / time_interval\n",
        "        subset_sums.append(packets_per_second)\n",
        "\n",
        "        if (end_index == packets_per_subset*20):\n",
        "            break\n",
        "\n",
        "    alternative_packets_per_second_sum.append(sum(subset_sums))"
      ],
      "metadata": {
        "id": "9f6sa72P9GFe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"feature 1: {num_total_packets}\")\n",
        "print(f\"feature 2: {sum_packets}\")\n",
        "print(f\"feature 3: {num_incoming_packets}\")\n",
        "print(f\"feature 4: {frac_incoming_packets}\")\n",
        "print(f\"feature 5: {num_outgoing_packets}\")\n",
        "print(f\"feature 6: {frac_outgoing_packets}\")"
      ],
      "metadata": {
        "id": "1rI6YCuJ9cSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'feature 7: {average_outgoing_ordering}');\n",
        "print(f'feature 8: {std_dev_outgoing_ordering}');\n",
        "print(f'feature 9: {average_incoming_ordering}');\n",
        "print(f'feature 10: {std_dev_incoming_ordering}');\n",
        "print(f'feature 11: {mean_of_the_sequence}');\n",
        "print(f\"feature 12: {alternative_packets_per_second_sum}\")"
      ],
      "metadata": {
        "id": "FZIIbew09cUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "incoming_packets_first30 =[] # feature 13\n",
        "outgoing_packets_first30 = [] # feature 14\n",
        "transmission_time_Q1 = [] # feature 15\n",
        "transmission_time_Q2 = [] # feature 16\n",
        "transmission_time_Q3 = [] # feature 17\n",
        "transmission_time_Q4 = [] # feature 18"
      ],
      "metadata": {
        "id": "zBTCL3QLJIma"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_packets_per_second = [] # feature 19\n",
        "mean_packets_per_second = [] # feature 20\n",
        "std_packets_per_second = [] # feature 21\n",
        "min_packets_per_second = [] # feature 22\n",
        "max_packets_per_second = [] # feature 23\n",
        "med_packets_per_second = [] # feature 24"
      ],
      "metadata": {
        "id": "ih6ONoHrLkgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for size_seq in X2:\n",
        "    incoming_packets = sum(1 for size in size_seq[:30] if size < 0)\n",
        "    incoming_packets_first30.append(incoming_packets)\n",
        "\n",
        "    outgoing_packets = sum(1 for size in size_seq[:30] if size > 0)\n",
        "    outgoing_packets_first30.append(outgoing_packets)\n",
        "\n",
        "print(\"incoming_packets_first30:\", incoming_packets_first30)\n",
        "print(\"outgoing_packets_first30:\", outgoing_packets_first30)"
      ],
      "metadata": {
        "id": "_uZNnP63JP0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(X1)):\n",
        "    Q1 = np.percentile(X1[i], 25)\n",
        "    Q2 = np.percentile(X1[i], 50)\n",
        "    Q3 = np.percentile(X1[i], 75)\n",
        "    Q4 = np.percentile(X1[i], 100)\n",
        "\n",
        "    transmission_time_Q1.append(Q1)\n",
        "    transmission_time_Q2.append(Q2)\n",
        "    transmission_time_Q3.append(Q3)\n",
        "    transmission_time_Q4.append(Q4)\n",
        "\n",
        "print(\"transmission_time_Q1:\", transmission_time_Q1)\n",
        "print(\"transmission_time_Q2:\", transmission_time_Q2)\n",
        "print(\"transmission_time_Q3:\", transmission_time_Q3)\n",
        "print(\"transmission_time_Q4:\", transmission_time_Q4)"
      ],
      "metadata": {
        "id": "eFMbO-0LJQTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import statistics\n",
        "\n",
        "for i in range(len(X1)):\n",
        "    num_packets = len(X1[i]) / X1[i][-1]\n",
        "    mean_packets = statistics.mean(X1[i])\n",
        "    std_packets = statistics.stdev(X1[i])\n",
        "    med_packets = statistics.median(X1[i])\n",
        "\n",
        "    num_packets_per_second.append(num_packets)\n",
        "    mean_packets_per_second.append(mean_packets)\n",
        "    std_packets_per_second.append(std_packets)\n",
        "    med_packets_per_second.append(med_packets)\n",
        "\n",
        "print(f\"Num Packets Per Second: {num_packets_per_second}\")\n",
        "print(f\"Mean Packets Per Second: {mean_packets_per_second}\")\n",
        "print(f\"Std Packets Per Second: {std_packets_per_second}\")\n",
        "print(f\"Med Packets Per Second: {med_packets_per_second}\")"
      ],
      "metadata": {
        "id": "JqiV4cr-L54A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = {'num_total_packets': num_total_packets,\n",
        "        'sum_packets': sum_packets,\n",
        "        'num_incoming_packets': num_incoming_packets,\n",
        "        'frac_incoming_packets': frac_incoming_packets,\n",
        "        'num_outgoing_packets': num_outgoing_packets,\n",
        "        'frac_outgoing_packets': frac_outgoing_packets,\n",
        "        'average_outgoing_ordering': average_outgoing_ordering,\n",
        "        'std_dev_outgoing_ordering': std_dev_outgoing_ordering,\n",
        "        'average_incoming_ordering': average_incoming_ordering,\n",
        "        'std_dev_incoming_ordering': std_dev_incoming_ordering,\n",
        "        'mean_of_the_sequence': mean_of_the_sequence,\n",
        "        'alternative_packets_per_second_sum': alternative_packets_per_second_sum}\n",
        "df1 = pd.DataFrame(data)\n",
        "\n",
        "print(df1.head())"
      ],
      "metadata": {
        "id": "_XVm_UAN9dmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "y = [-1] * 10000\n",
        "data = {'label': y}\n",
        "df2 = pd.DataFrame(data)\n",
        "\n",
        "print(df2.head())"
      ],
      "metadata": {
        "id": "8puMiprM9fhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.to_csv('unmon_features.csv', index=False)"
      ],
      "metadata": {
        "id": "3PZX9mgH9gNU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.to_csv('unmon_labels.csv', index=False)"
      ],
      "metadata": {
        "id": "JTcAtmZ69huk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data_modified = {'num_total_packets': num_total_packets, #1\n",
        "                 'sum_packets': sum_packets, #2\n",
        "                 'num_incoming_packets': num_incoming_packets, #3\n",
        "                 'frac_incoming_packets': frac_incoming_packets, #4\n",
        "                 'num_outgoing_packets': num_outgoing_packets, #5\n",
        "                 'frac_outgoing_packets': frac_outgoing_packets, #6\n",
        "                 'average_outgoing_ordering': average_outgoing_ordering, #7\n",
        "                 'std_dev_outgoing_ordering': std_dev_outgoing_ordering, #8\n",
        "                 'average_incoming_ordering': average_incoming_ordering, #9\n",
        "                 'std_dev_incoming_ordering': std_dev_incoming_ordering, #10\n",
        "                 'mean_of_the_sequence': mean_of_the_sequence, #11\n",
        "                 'alternative_packets_per_second_sum': alternative_packets_per_second_sum, #12\n",
        "                 'incoming_packets_first30': incoming_packets_first30, #13\n",
        "                 'outgoing_packets_first30': outgoing_packets_first30, #14\n",
        "                 'transmission_time_Q1': transmission_time_Q1, #15\n",
        "                 'transmission_time_Q2': transmission_time_Q2, #16\n",
        "                 'transmission_time_Q3': transmission_time_Q3, #17\n",
        "                 'transmission_time_Q4': transmission_time_Q4, #18\n",
        "                 'num_packets_per_second': num_packets_per_second, #19\n",
        "                 'mean_packets_per_second': mean_packets_per_second, #20\n",
        "                 'std_packets_per_second': std_packets_per_second, #21\n",
        "                 'med_packets_per_second': med_packets_per_second #22\n",
        "                 }\n",
        "df1_modified = pd.DataFrame(data_modified)\n",
        "\n",
        "print(df1_modified.head())"
      ],
      "metadata": {
        "id": "mmUYM8nqJm4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1_modified.to_csv('unmon_features_modified.csv', index=False)"
      ],
      "metadata": {
        "id": "D_vnzhl-JtsB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}